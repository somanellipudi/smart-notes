# Smart Notes - Complete Guide

## ğŸ“š Project Overview

Smart Notes is a **multi-stage GenAI reasoning pipeline** for structured understanding of classroom content. It processes audio lectures, notes, equations, and context to produce comprehensive educational analysis through 7 independent reasoning stages.

### What It Does
- **Audio Processing**: Transcribes lectures using OpenAI Whisper
- **Image OCR**: Extracts text from handwritten notes, blackboard, and whiteboard photos
- **Text Processing**: Segments and normalizes content from multiple sources
- **Multi-Stage Reasoning**: 7 independent reasoning stages extract:
  1. Topic Identification
  2. Concept Extraction
  3. Equation Interpretation
  4. Misconception Detection
  5. FAQ Generation
  6. Real-World Connections
  7. Worked Example Analysis
- **Quality Evaluation**: 4-metric evaluation framework assesses output
- **Session Management**: Persists data and generates cumulative study guides
- **Web UI**: Streamlit interface for easy interaction

### Key Features
âœ… Multi-stage reasoning (not single prompt)  
âœ… Structured JSON output with Pydantic validation  
âœ… Production-grade logging with rotation  
âœ… Environment-based configuration  
âœ… Session persistence and aggregation  
âœ… Educational metrics evaluation  

---

## ğŸš€ Quick Start (2â€“3 minutes)

### 1. Create & Activate Virtual Environment
```bash
python -m venv .venv
# Windows PowerShell
.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure API Key
Add your key to .env:
```ini
OPENAI_API_KEY=sk-your-key-here
```

### 4. Run Application
```bash
python -m streamlit run app.py
```

**Access at**: http://localhost:8501

---

## ğŸ“‹ Requirements

- Python 3.8+
- OpenAI API key (free tier works)
- 2GB RAM minimum
- Internet connection

---

## âš™ï¸ Installation & Setup

### Step 1: Create & Activate Virtual Environment
```bash
python -m venv .venv
# Windows PowerShell
.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Configure API Keys

1. Get API key from https://platform.openai.com/api-keys
2. Edit `.env`:
    ```ini
    OPENAI_API_KEY=sk-your-key-here
    ```
3. Run:
    ```bash
    python -m streamlit run app.py
    ```

### Step 4: Verify Setup
```bash
python test_config.py
```

Expected output:
```
âœ“ Configuration loaded successfully!
    ENVIRONMENT: development
    DEBUG: True
```

---

## ğŸ® How to Use

### Web Interface (Recommended)

```bash
streamlit run app.py
```

**Features:**
1. **Example Runner** - Try pre-built examples with one click
2. **Manual Input** - Upload audio/notes or paste content
3. **Structured Output** - 9 sections of analysis
4. **Session History** - View past sessions
5. **Study Guide** - Generate cumulative study materials

### CLI Usage

```python
from src.reasoning.pipeline import ReasoningPipeline

pipeline = ReasoningPipeline()
result = pipeline.process(
    audio_transcript="Lecture content here...",
    notes="Student notes here...",
    equations=["y = mx + b", "F = ma"],
    context="Additional context..."
)

print(result.to_dict())
```

### Example Script

```bash
python examples/demo_usage.py
```

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ app.py                          # Streamlit web interface
â”œâ”€â”€ config.py                       # Configuration management
â”œâ”€â”€ requirements.txt                # Dependencies
â”‚
â”œâ”€â”€ .env                            # Configuration (git-ignored)
â”œâ”€â”€ .env.example                    # Configuration template
â”œâ”€â”€ .gitignore                      # Git protection
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â””â”€â”€ transcription.py        # Audio to text (Whisper)
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ text_processing.py      # Text segmentation & normalization
â”‚   â”œâ”€â”€ reasoning/
â”‚   â”‚   â””â”€â”€ pipeline.py             # 7-stage reasoning pipeline
â”‚   â”œâ”€â”€ schema/
â”‚   â”‚   â””â”€â”€ output_schema.py        # Pydantic validation models
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ metrics.py              # Quality evaluation (4 metrics)
â”‚   â”œâ”€â”€ study_book/
â”‚   â”‚   â””â”€â”€ session_manager.py      # Session persistence
â”‚   â””â”€â”€ logging_config.py           # Production logging
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ demo_usage.py               # CLI example
â”‚   â”œâ”€â”€ inputs/                     # Sample data
â”‚   â””â”€â”€ notes/                      # Sample notes
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cache/                      # Cache files
â”‚   â””â”€â”€ audio_cache/                # Audio cache
â”‚
â”œâ”€â”€ logs/                           # Application logs
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ sessions/                   # Session data
â”‚
â””â”€â”€ docs/
    â””â”€â”€ GUIDE.md                    # This file
```

---

## âš™ï¸ Configuration

### Core Settings

Edit `.env` to customize:

```ini
# Environment
ENVIRONMENT=development              # development, staging, production
DEBUG=true                          # Enable debug mode

# API
OPENAI_API_KEY=sk-your-key          # Your API key
LLM_MODEL=gpt-4                     # Model: gpt-4 or gpt-3.5-turbo

# Features
LOG_LEVEL=DEBUG                     # DEBUG, INFO, WARNING, ERROR

# Reasoning Pipeline
MAX_TOPICS=10                        # Max topics to extract
MAX_FAQS=15                          # FAQ items to generate
MAX_WORKED_EXAMPLES=5               # Example problems
```

**See `.env.example` for 100+ configuration options**

---

## ğŸ”§ Architecture

### 7-Stage Reasoning Pipeline

Each stage is independent and produces structured output:

```
Input (audio, notes, equations, context)
    â†“
1ï¸âƒ£ Topic Identification
    Extracts major topics covered
    â†“
2ï¸âƒ£ Concept Extraction
    Identifies key concepts per topic
    â†“
3ï¸âƒ£ Equation Interpretation
    Converts equations to plain language
    â†“
4ï¸âƒ£ Misconception Detection
    Identifies common student mistakes
    â†“
5ï¸âƒ£ FAQ Generation
    Creates frequently asked questions
    â†“
6ï¸âƒ£ Real-World Connections
    Links to practical applications
    â†“
7ï¸âƒ£ Worked Example Analysis
    Provides example problem solutions
    â†“
Output (Structured JSON with all 7 stages)
```

### Processing Flow

```
Audio File
    â†“
Whisper (Audio â†’ Text)
    â†“
Text Processor (Segmentation, Normalization)
    â†“
Reasoning Pipeline (7 Stages)
    â†“
Evaluator (4 Quality Metrics)
    â†“
Output Schema (Pydantic Validation)
    â†“
Session Manager (Persistence)
    â†“
JSON Output + Study Guide
```

### 4-Metric Evaluation

Output quality is evaluated on:

1. **Reasoning Correctness** (0-1)
   - Accuracy of concepts and analysis

2. **Structural Accuracy** (0-1)
   - Correct JSON schema and organization

3. **Hallucination Rate** (0-1)
   - Percentage of fabricated information

4. **Educational Usefulness** (1-5)
   - How helpful for learning

Thresholds set in `.env`:
```ini
MIN_REASONING_CORRECTNESS=0.7
MIN_STRUCTURAL_ACCURACY=0.8
MAX_HALLUCINATION_RATE=0.15
MIN_EDUCATIONAL_USEFULNESS=3.5
```

---

## ğŸ“Š Input & Output

### Input Format

**Audio + Text + Context:**
```python
{
    "audio_file": "lecture.wav",
    "notes": "Student notes...",
    "equations": ["E = mcÂ²", "F = ma"],
    "context": "Additional context..."
}
```

**Image Upload (NEW!):**
```python
{
    "images": ["notes1.jpg", "whiteboard.png", "blackboard.jpg"],
    "audio_file": "lecture.wav",  # Optional
    "equations": ["..."],
    "context": "..."
}
```

### ğŸ“¸ Image OCR Feature

Upload photos of handwritten notes, blackboard, or whiteboard and automatically extract text!

**Supported Formats:**
- JPG, JPEG, PNG, BMP
- Multiple images supported
- Handwritten notes
- Blackboard/whiteboard photos
- Printed documents

**How to Use:**
1. Open the Streamlit app
2. Select "Upload Images" option
3. Click "Browse files" and select your images
4. Preview thumbnails to verify upload
5. Click "Process Session" to extract text

**OCR Backend:**
- **Primary**: EasyOCR (deep learning-based, high accuracy)
- **Fallback**: Tesseract OCR (traditional OCR)
**Tips for Best Results:**
- Use good lighting
- Avoid shadows and glare
- Clear, legible handwriting
- High-resolution photos (recommended)
- Straight-on angle (not tilted)

**Image Preprocessing:**
- Automatic grayscale conversion
- Contrast enhancement
- Noise reduction
- Binarization for text detection

**Example:**
```bash
# 1. Start app
streamlit run app.py

# 2. Select "Upload Images"
# 3. Upload: lecture_notes.jpg, board_photo.png
# 4. Process â†’ Text extracted automatically!
```

**Installation:**
```bash
pip install easyocr Pillow opencv-python-headless
```

### Output Format

**Structured JSON with 7 sections:**
```json
{
    "session_id": "2024-01-15-123456",
    "topics": [
        {
            "name": "Calculus",
            "concepts": ["Derivatives", "Limits"],
            "equations": [...]
        }
    ],
    "faqs": [...],
    "misconceptions": [...],
    "worked_examples": [...],
    "evaluation": {
        "reasoning_correctness": 0.92,
        "hallucination_rate": 0.08
    }
}
```

---

## ğŸ“ Usage Examples

### Example 1: Run Pre-Built Demo
```bash
streamlit run app.py
```
Click "Example Runner" â†’ Select example â†’ See results

### Example 2: Upload Your Own
```bash
streamlit run app.py
```
Upload audio file + notes â†’ Process â†’ View results

### Example 3: CLI Processing
```python
from src.reasoning.pipeline import ReasoningPipeline

pipeline = ReasoningPipeline()
result = pipeline.process(
    audio_transcript="Learning about derivatives...",
    notes="Chain rule: d/dx[f(g(x))] = f'(g(x))Â·g'(x)",
    equations=["d/dx[xÂ²] = 2x"],
    context="Calculus lecture"
)

print(result.topics)
print(result.evaluation)
```

---

## ğŸš€ Running

### Production (Real API)
```bash
# 1. Add API key to .env
OPENAI_API_KEY=sk-your-real-key

# 2. Run
streamlit run app.py
```

---

## ğŸ“Š Logging

### Access Logs
```bash
# View latest logs
tail -f logs/smart_notes_*.log

# Search for errors
grep ERROR logs/smart_notes_*.log

# View today's logs
tail -100 logs/smart_notes_$(date +%Y-%m-%d).log
```

### Log Levels
- **DEBUG**: Detailed execution info (development)
- **INFO**: Important events (default)
- **WARNING**: Warning messages
- **ERROR**: Error messages only

Change log level:
```ini
# .env
LOG_LEVEL=DEBUG      # Verbose
LOG_LEVEL=INFO       # Normal
LOG_LEVEL=WARNING    # Errors only
```

---

## ğŸ” Testing

### Verify Configuration
```bash
python test_config.py
```

### Run with Example Data
```bash
# Via web UI
streamlit run app.py
# Click "Example Runner"

# Via CLI
python examples/demo_usage.py
```

### Test Each Component
```python
# Test transcription
from src.audio.transcription import AudioTranscriber
transcriber = AudioTranscriber()
text = transcriber.transcribe("audio.wav")

# Test preprocessing
from src.preprocessing.text_processing import TextPreprocessor
processor = TextPreprocessor()
segments = processor.process("lecture text")

# Test reasoning
from src.reasoning.pipeline import ReasoningPipeline
pipeline = ReasoningPipeline()
result = pipeline.process(audio_transcript=segments)

# Test evaluation
from src.evaluation.metrics import ContentEvaluator
evaluator = ContentEvaluator()
score = evaluator.evaluate(result)
```

---

## ğŸ› Troubleshooting

### App Won't Start
```bash
# 1. Check config
python test_config.py

# 2. Check dependencies
pip install -r requirements.txt

# 3. Run with debug
DEBUG=true streamlit run app.py
```

### API Errors
```bash
# 1. Verify API key
echo $OPENAI_API_KEY

# 2. Check logs
tail -f logs/smart_notes_*.log
```

### Logs Not Creating
```bash
# 1. Check directory exists
ls -la logs/

# 2. Check permissions
chmod 755 logs/

# 3. Check LOG_OUTPUT setting
grep LOG_OUTPUT .env
```

### Out of Memory
```bash
# Reduce limits in .env
MAX_TOPICS=5
MAX_FAQS=8
WHISPER_MODEL_SIZE=tiny
```

---

## ğŸ“š API Keys & Costs

### Getting OpenAI API Key

1. Visit https://platform.openai.com/api-keys
2. Click "Create new secret key"
3. Copy key (shown only once)
4. Add to `.env`: `OPENAI_API_KEY=sk-...`

### Pricing (Jan 2024)

**Models:**
- GPT-4: $0.03/1K input, $0.06/1K output
- GPT-3.5-turbo: $0.0005/1K input, $0.0015/1K output

**Recommendation:**
- Testing: Use gpt-3.5-turbo ($0.001-0.01 per request)
- Production: Use gpt-4 (better quality)

---

## ğŸ” Security

### Keep Safe
âœ… Never share `.env` file  
âœ… Never commit `.env` to git (already in .gitignore)  
âœ… Rotate API keys regularly  
âœ… Use different keys per environment  

### Protecting Your Key
```bash
# Check if .env is protected
git status
# Should show: nothing added to commit

# Verify .gitignore works
cat .gitignore | grep ".env"
```

---

## ğŸ¤ File Descriptions

| File | Purpose |
|------|---------|
| `app.py` | Streamlit web interface |
| `config.py` | Configuration loader (reads .env) |
| `src/audio/transcription.py` | Audio â†’ Text via Whisper |
| `src/preprocessing/text_processing.py` | Segment & normalize text |
| `src/reasoning/pipeline.py` | 7-stage reasoning (core logic) |
| `src/schema/output_schema.py` | Pydantic validation models |
| `src/evaluation/metrics.py` | Quality evaluation (4 metrics) |
| `src/study_book/session_manager.py` | Session persistence |
| `src/logging_config.py` | Production logging setup |
| `examples/demo_usage.py` | CLI example |
| `test_config.py` | Configuration validator |

---

## âœ… Common Tasks

### Try an Example
```bash
streamlit run app.py
# Click "Example Runner" â†’ Select example
```

### Process Your Own Audio
```bash
streamlit run app.py
# Upload audio + notes â†’ Process
```

### Change API Model
Edit `.env`:
```ini
# Fast & Cheap
LLM_MODEL=gpt-3.5-turbo
LLM_TEMPERATURE=0.3

# Smart & Expensive
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.2
```

### Enable Debug Logging
```bash
DEBUG=true LOG_LEVEL=DEBUG streamlit run app.py
```

### Generate Study Guide
```bash
streamlit run app.py
# Process sessions â†’ Click "Generate Cumulative Study Guide"
```

---

## ğŸ“ Support

### Check Status
```bash
python test_config.py
```

### View Logs
```bash
tail -f logs/smart_notes_*.log
```

### Test Components
```bash
python -c "from src.reasoning.pipeline import ReasoningPipeline; print('âœ“ Pipeline OK')"
```

### Reset to Defaults
```bash
rm .env
cp .env.example .env
```

---

## ğŸ¯ Next Steps

1. âœ… Install dependencies: `pip install -r requirements.txt`
2. âœ… Test config: `python test_config.py`
3. âœ… Run app: `streamlit run app.py`
4. âœ… Try examples: Click "Example Runner"
5. âœ… Upload your content: Use file uploaders

---

## ğŸ“Š What You Can Do

- âœ… Extract topics from lectures
- âœ… Identify key concepts
- âœ… Explain equations in plain language
- âœ… Find common misconceptions
- âœ… Generate frequently asked questions
- âœ… Connect to real-world applications
- âœ… Provide worked example solutions
- âœ… Evaluate content quality
- âœ… Build cumulative study guides
- âœ… Manage multiple sessions

---

## ğŸš€ Quick Reference

```bash
# Setup
pip install -r requirements.txt
python test_config.py

# Run
streamlit run app.py

# View Logs
tail -f logs/smart_notes_*.log

# Test Config
python test_config.py

# CLI Example
python examples/demo_usage.py

# Add API Key
# Edit .env: OPENAI_API_KEY=sk-...
```

---

## ğŸ“– Version Info

- **Created**: 2024
- **Language**: Python 3.8+
- **Framework**: Streamlit
- **LLM**: OpenAI (GPT-4 / GPT-3.5-turbo)
- **Audio**: OpenAI Whisper
- **Status**: âœ… Production Ready

