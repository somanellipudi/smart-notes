# Smart Notes: File Structure & Organization Guide

**Version**: 2.0 (Production-Ready)  
**Date**: February 12, 2026  
**Purpose**: Complete visual guide to file organization and module dependencies

---

## Table of Contents

1. [Complete File Tree](#complete-file-tree)
2. [Directory Organization](#directory-organization)
3. [Module Dependency Graph](#module-dependency-graph)
4. [File Categories & Purposes](#file-categories--purposes)
5. [Import Patterns](#import-patterns)
6. [Configuration & Secrets](#configuration--secrets)
7. [Cache & Output Directories](#cache--output-directories)
8. [Test Organization](#test-organization)
9. [Documentation Files](#documentation-files)

---

## Complete File Tree

```
Smart-Notes/
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  ROOT-LEVEL FILES (Configuration & Entry Points)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“„ app.py                                  â­ PRIMARY ENTRY POINT
â”‚   â”‚  Lines: 1600+
â”‚   â”‚  Purpose: Streamlit UI, main application
â”‚   â”‚  Dependencies: streamlit, src.*, config
â”‚   â”‚  Exports: Web interface on localhost:8501
â”‚   â”‚  Status: Production-ready (v2.0)
â”‚   â”‚
â”‚
â”œâ”€â”€ ğŸ”‘ config.py                               âš™ï¸ CONFIGURATION
â”‚   â”‚  Lines: ~150
â”‚   â”‚  Purpose: Global parameters and thresholds
â”‚   â”‚  Key vars: VERIFIED_THRESHOLD, MODEL_NAMES, CACHE_DIR
â”‚   â”‚  Used by: All src/* modules
â”‚   â”‚  Status: Production-ready
â”‚   â”‚
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt                        ğŸ“¦ DEPENDENCIES
â”‚   â”‚  Lines: 25+
â”‚   â”‚  Contains: Python packages + versions
â”‚   â”‚  Install: pip install -r requirements.txt
â”‚   â”‚  Categories:
â”‚   â”‚    - Core: streamlit, pandas, numpy
â”‚   â”‚    - ML: transformers, torch, sentence-transformers
â”‚   â”‚    - Graph: networkx, pyvis
â”‚   â”‚    - Optional: pyarrow, matplotlib, easycr
â”‚   â”‚
â”‚
â”œâ”€â”€ ğŸ” .env                                    ğŸ”’ SECRETS (GITIGNORE)
â”‚   â”‚  Created by user from .env.example
â”‚   â”‚  Contains: API_KEY, LLM_PROVIDER, etc.
â”‚   â”‚  Status: Never committed to git
â”‚   â”‚
â”‚
â”œâ”€â”€ ğŸ“„ .env.example                            ğŸ“„ SECRETS TEMPLATE
â”‚   â”‚  Template for creating .env file
â”‚   â”‚  Shows required environment variables
â”‚   â”‚
â”‚
â”œâ”€â”€ .gitignore                                 ğŸ“ GIT EXCLUSIONS
â”‚   â”‚  Excludes: .env, __pycache__, *.pyc, .venv
â”‚   â”‚
â”‚
â”œâ”€â”€ README.md                                  ğŸ“– USER DOCUMENTATION
â”‚   â”‚  Lines: 1585+
â”‚   â”‚  Audience: End users, researchers
â”‚   â”‚  Contents: Quick start, installation, usage
â”‚   â”‚  Status: Updated Feb 2025
â”‚   â”‚
â”‚
â”œâ”€â”€ LICENSE                                    ğŸ“œ MIT LICENSE
â”‚   â”‚
â”‚
â””â”€â”€ validate_fixes.py                          ğŸ” VALIDATION SCRIPT âœ¨ NEW
    â”‚  Lines: ~200
    â”‚  Purpose: Test environment and verify all fixes work
    â”‚  Usage: python validate_fixes.py
    â”‚  Status: Comprehensive validation (Feb 2025)
    â”‚
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  src/ DIRECTORY (8,000+ lines of application code)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                         (Empty Python package marker)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ llm_provider.py                     ğŸ¤– LLM ABSTRACTION LAYER
â”‚   â”‚   â”‚  Lines: ~200
â”‚   â”‚   â”‚  Purpose: Unified interface for OpenAI/Ollama
â”‚   â”‚   â”‚  Classes:
â”‚   â”‚   â”‚    - LLMProvider (base interface)
â”‚   â”‚   â”‚    - OpenAIProvider
â”‚   â”‚   â”‚    - OllamaProvider
â”‚   â”‚   â”‚  Key methods: generate(), generate_json()
â”‚   â”‚   â”‚  Used by: reasoning/pipeline.py
â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ logging_config.py                   ğŸ“Š LOGGING SETUP
â”‚   â”‚   â”‚  Lines: ~50
â”‚   â”‚   â”‚  Purpose: Configure logging to files + console
â”‚   â”‚   â”‚  Output files:
â”‚   â”‚   â”‚    - logs/app.log (all messages)
â”‚   â”‚   â”‚    - logs/errors.log (errors only)
â”‚   â”‚   â”‚  Used by: All modules (logger = logging.getLogger(__name__))
â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ output_formatter.py                 ğŸ“¤ EXPORT FORMATTING
â”‚   â”‚   â”‚  Lines: ~300
â”‚   â”‚   â”‚  Purpose: Format results into JSON/CSV/Markdown
â”‚   â”‚   â”‚  Classes: OutputFormatter
â”‚   â”‚   â”‚  Methods:
â”‚   â”‚   â”‚    - to_json(results) â†’ JSON bytes
â”‚   â”‚   â”‚    - to_csv(results) â†’ CSV bytes
â”‚   â”‚   â”‚    - to_markdown(results) â†’ Markdown bytes
â”‚   â”‚   â”‚  Used by: app.py, reasoning/pipeline.py
â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ streamlit_display.py               ğŸ¨ UI UTILITIES
â”‚   â”‚   â”‚  Lines: ~150
â”‚   â”‚   â”‚  Purpose: Streamlit-specific display utilities
â”‚   â”‚   â”‚  Functions:
â”‚   â”‚   â”‚    - display_metrics_dashboard(results)
â”‚   â”‚   â”‚    - display_claims_table(claims)
â”‚   â”‚   â”‚    - display_graph(graph)
â”‚   â”‚   â”‚  Used by: app.py
â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ claims/                            âœ¨ CLAIMS MANAGEMENT
â”‚   â”‚   â”‚  Purpose: Extract, verify, and analyze claims
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ schema.py                       ğŸ“Š DATA MODELS
â”‚   â”‚   â”‚   â”‚  Lines: 493
â”‚   â”‚   â”‚   â”‚  Classes:
â”‚   â”‚   â”‚   â”‚    - VerificationStatus (enum)
â”‚   â”‚   â”‚   â”‚    - ClaimType (enum)
â”‚   â”‚   â”‚   â”‚    - EvidenceItem (Pydantic model)
â”‚   â”‚   â”‚   â”‚    - LearningClaim (Pydantic model)
â”‚   â”‚   â”‚   â”‚    - GraphMetrics (Pydantic model)
â”‚   â”‚   â”‚   â”‚        â”œâ”€ .to_dict() method âœ¨ NEW
â”‚   â”‚   â”‚   â”‚        â””â”€ .get() method âœ¨ NEW
â”‚   â”‚   â”‚   â”‚    - SessionResult (Pydantic model)
â”‚   â”‚   â”‚   â”‚  Used by: All claims/* modules
â”‚   â”‚   â”‚   â”‚  Status: Production-ready (Feb 2025)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ extractor.py                    ğŸ” CLAIM EXTRACTION
â”‚   â”‚   â”‚   â”‚  Lines: ~200
â”‚   â”‚   â”‚   â”‚  Purpose: Parse LLM output into discrete claims
â”‚   â”‚   â”‚   â”‚  Classes: ClaimExtractor
â”‚   â”‚   â”‚   â”‚  Methods: extract(json_output) â†’ List[LearningClaim]
â”‚   â”‚   â”‚   â”‚  Pattern: Regex + NLP tokenization
â”‚   â”‚   â”‚   â”‚  Used by: reasoning/pipeline.py, reasoning/verifiable_pipeline.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ validator.py                    âœ… STATUS ASSIGNMENT
â”‚   â”‚   â”‚   â”‚  Lines: ~150
â”‚   â”‚   â”‚   â”‚  Purpose: Assign verification status based on confidence
â”‚   â”‚   â”‚   â”‚  Thresholds:
â”‚   â”‚   â”‚   â”‚    - confidence â‰¥ 0.7 â†’ VERIFIED
â”‚   â”‚   â”‚   â”‚    - 0.3 â‰¤ confidence < 0.7 â†’ LOW_CONFIDENCE
â”‚   â”‚   â”‚   â”‚    - confidence < 0.3 â†’ REJECTED
â”‚   â”‚   â”‚   â”‚  Classes: ClaimValidator
â”‚   â”‚   â”‚   â”‚  Used by: reasoning/verifiable_pipeline.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ nli_verifier.py                 ğŸ§  NLI CLASSIFICATION âœ¨ NEW
â”‚   â”‚   â”‚   â”‚  Lines: 266
â”‚   â”‚   â”‚   â”‚  Purpose: Verify entailment using BART-MNLI
â”‚   â”‚   â”‚   â”‚  Classes: NLIVerifier
â”‚   â”‚   â”‚   â”‚  Models:
â”‚   â”‚   â”‚   â”‚    - facebook/bart-large-mnli (1.6GB)
â”‚   â”‚   â”‚   â”‚    - Alternative: roberta-large-mnli
â”‚   â”‚   â”‚   â”‚  Methods:
â”‚   â”‚   â”‚   â”‚    - verify_entailment(claim, evidence)
â”‚   â”‚   â”‚   â”‚    - multi_source_consensus(claim, evidence_list)
â”‚   â”‚   â”‚   â”‚  Output:
â”‚   â”‚   â”‚   â”‚    - label âˆˆ {ENTAILMENT, CONTRADICTION, NEUTRAL}
â”‚   â”‚   â”‚   â”‚    - probabilities for each label
â”‚   â”‚   â”‚   â”‚  Used by: reasoning/verifiable_pipeline.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready (Feb 2025)
â”‚   â”‚   â”‚   â”‚  Performance: ~200ms per (claim, evidence) pair
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ confidence.py                    ğŸ“Š CONFIDENCE SCORING âœ¨ NEW
â”‚       â”‚  Lines: 304
â”‚       â”‚  Purpose: Calculate multi-factor confidence scores
â”‚       â”‚  Classes: ConfidenceCalculator
â”‚       â”‚  Components:
â”‚       â”‚    - Semantic similarity (25% weight)
â”‚       â”‚    - Entailment probability (35%)
â”‚       â”‚    - Source diversity (10%)
â”‚       â”‚    - Evidence count (15%)
â”‚       â”‚    - Contradiction penalty (-10%)
â”‚       â”‚    - Graph centrality (5%)
â”‚       â”‚  Methods:
â”‚       â”‚    - compute_confidence() â†’ float âˆˆ [0, 1]
â”‚       â”‚    - fit_temperature() (calibration)
â”‚       â”‚  Used by: reasoning/verifiable_pipeline.py
â”‚       â”‚  Status: Production-ready (Feb 2025)
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ retrieval/                         ğŸ” EVIDENCE RETRIEVAL
â”‚   â”‚   â”‚  Purpose: Search and rank evidence from source material
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ claim_rag.py                    ğŸ” KEYWORD RETRIEVAL (DEPRECATED)
â”‚   â”‚   â”‚   â”‚  Lines: ~150
â”‚   â”‚   â”‚   â”‚  Purpose: Legacy keyword-based search (Jaccard similarity)
â”‚   â”‚   â”‚   â”‚  Status: Deprecated (use semantic_retriever.py)
â”‚   â”‚   â”‚   â”‚  Kept for: Backward compatibility
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ semantic_retriever.py           ğŸ§  SEMANTIC RETRIEVAL âœ¨ NEW
â”‚       â”‚  Lines: 296
â”‚       â”‚  Purpose: Dense retrieval with FAISS + cross-encoder re-ranking
â”‚       â”‚  Models:
â”‚       â”‚    - intfloat/e5-base-v2 (400MB) for embeddings
â”‚       â”‚    - cross-encoder/ms-marco-MiniLM-L-6-v2 (80MB) for ranking
â”‚       â”‚  Classes: SemanticRetriever
â”‚       â”‚  Methods:
â”‚       â”‚    - index_corpus(documents) â†’ build FAISS index
â”‚       â”‚    - retrieve(query) â†’ List[EvidenceItem]
â”‚       â”‚  Performance:
â”‚       â”‚    - FAISS search: ~100ms (k=10)
â”‚       â”‚    - Cross-encoder re-rank: ~400ms (n=5)
â”‚       â”‚    - Per-claim: ~500ms
â”‚       â”‚  Used by: reasoning/verifiable_pipeline.py
â”‚       â”‚  Status: Production-ready (Feb 2025)
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ reasoning/                         ğŸ’¡ LLM PIPELINES
â”‚   â”‚   â”‚  Purpose: Orchestrate LLM generation and verification
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ pipeline.py                     ğŸ”„ BASELINE PIPELINE
â”‚   â”‚   â”‚   â”‚  Lines: ~300
â”‚   â”‚   â”‚   â”‚  Purpose: Fast generation without verification
â”‚   â”‚   â”‚   â”‚  Pipeline:
â”‚   â”‚   â”‚   â”‚    1. Call LLM with 7-stage prompt
â”‚   â”‚   â”‚   â”‚    2. Parse JSON output
â”‚   â”‚   â”‚   â”‚    3. Extract claims
â”‚   â”‚   â”‚   â”‚    4. Format output
â”‚   â”‚   â”‚   â”‚  Classes: BaselinePipeline
â”‚   â”‚   â”‚   â”‚  Speed: 20-40 seconds for ~300 claims
â”‚   â”‚   â”‚   â”‚  Used by: app.py, reasoning/verifiable_pipeline.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ verifiable_pipeline.py          ğŸ”¬ VERIFIABLE PIPELINE âœ¨ NEW
â”‚   â”‚   â”‚   â”‚  Lines: ~400
â”‚   â”‚   â”‚   â”‚  Purpose: Generate + verify claims against source
â”‚   â”‚   â”‚   â”‚  Pipeline:
â”‚   â”‚   â”‚   â”‚    1. Generate claims (BaselinePipeline)
â”‚   â”‚   â”‚   â”‚    2. Index source corpus (SemanticRetriever)
â”‚   â”‚   â”‚   â”‚    3. Retrieve evidence per claim (SemanticRetriever)
â”‚   â”‚   â”‚   â”‚    4. Verify entailment (NLIVerifier)
â”‚   â”‚   â”‚   â”‚    5. Calculate confidence (ConfidenceCalculator)
â”‚   â”‚   â”‚   â”‚    6. Assign status (ClaimValidator)
â”‚   â”‚   â”‚   â”‚    7. Build graph (ClaimGraph)
â”‚   â”‚   â”‚   â”‚    8. Compute metrics (GraphMetrics)
â”‚   â”‚   â”‚   â”‚  Classes: VerifiablePipeline
â”‚   â”‚   â”‚   â”‚  Speed: 60-120 seconds for ~300 claims
â”‚   â”‚   â”‚   â”‚  Used by: app.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready (Feb 2025)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ prompts.py                      ğŸ“ LLM PROMPTS
â”‚       â”‚  Lines: ~200
â”‚       â”‚  Purpose: Store and manage LLM prompt templates
â”‚       â”‚  Prompts:
â”‚       â”‚    - 7-stage generation pipeline
â”‚       â”‚    - Extraction pattern prompts
â”‚       â”‚  Used by: reasoning/pipeline.py
â”‚       â”‚  Status: Production-ready
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ graph/                             ğŸ“ˆ GRAPH ANALYSIS
â”‚   â”‚   â”‚  Purpose: Build, analyze, and export knowledge graphs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ claim_graph.py                  ğŸ”— GRAPH CONSTRUCTION
â”‚   â”‚   â”‚   â”‚  Lines: 727
â”‚   â”‚   â”‚   â”‚  Purpose: Build NetworkX DiGraph from claims
â”‚   â”‚   â”‚   â”‚  Classes: ClaimGraph
â”‚   â”‚   â”‚   â”‚  Graph structure:
â”‚   â”‚   â”‚   â”‚    - Nodes: Claims (blue) + Evidence (green)
â”‚   â”‚   â”‚   â”‚    - Edges: claim â†’ evidence (weight = similarity)
â”‚   â”‚   â”‚   â”‚    - Attributes: status, confidence, snippet, etc.
â”‚   â”‚   â”‚   â”‚  Methods:
â”‚   â”‚   â”‚   â”‚    - compute_metrics() â†’ GraphMetrics
â”‚   â”‚   â”‚   â”‚    - export_graphml() â†’ bytes
â”‚   â”‚   â”‚   â”‚    - export_adjacency_json() â†’ str
â”‚   â”‚   â”‚   â”‚    - visualize() â†’ Image (PNG if matplotlib)
â”‚   â”‚   â”‚   â”‚  Metrics computed:
â”‚   â”‚   â”‚   â”‚    - Redundancy (evidence per claim)
â”‚   â”‚   â”‚   â”‚    - Diversity (source variety)
â”‚   â”‚   â”‚   â”‚    - Support depth (max path length)
â”‚   â”‚   â”‚   â”‚    - Conflict count (contradictions)
â”‚   â”‚   â”‚   â”‚    - Centrality (claim importance)
â”‚   â”‚   â”‚   â”‚  Used by: reasoning/verifiable_pipeline.py, app.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ graph_sanitize.py               ğŸ§¹ SANITIZATION âœ¨ NEW (Feb 2025)
â”‚       â”‚  Lines: 166
â”‚       â”‚  Purpose: Sanitize graph for GraphML export (handles bytes/enums/Pydantic)
â”‚       â”‚  Classes: None (functions only)
â”‚       â”‚  Functions:
â”‚       â”‚    - _sanitize_value() â†’ GraphML-safe string
â”‚       â”‚    - sanitize_graph_for_graphml() â†’ sanitized copy
â”‚       â”‚    - export_graphml_string() â†’ XML string
â”‚       â”‚    - export_graphml_bytes() â†’ UTF-8 bytes
â”‚       â”‚  Handles:
â”‚       â”‚    - bytes â†’ UTF-8 decode or base64
â”‚       â”‚    - enums â†’ string values
â”‚       â”‚    - Pydantic models â†’ JSON
â”‚       â”‚    - dicts/lists â†’ JSON strings
â”‚       â”‚    - long strings â†’ truncated to 500 chars
â”‚       â”‚  Fixes: Graph export "bytes" TypeError (Issue #3)
â”‚       â”‚  Used by: graph/claim_graph.py, app.py
â”‚       â”‚  Status: Fully tested (18 unit tests)
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ preprocessing/                     âš™ï¸ INPUT PROCESSING
â”‚   â”‚   â”‚  Purpose: Clean and normalize input text
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ text_processor.py               ğŸ“ TEXT CLEANING
â”‚   â”‚   â”‚   â”‚  Lines: ~100
â”‚   â”‚   â”‚   â”‚  Purpose: Clean, normalize, and tokenize text
â”‚   â”‚   â”‚   â”‚  Classes: TextProcessor
â”‚   â”‚   â”‚   â”‚  Methods:
â”‚   â”‚   â”‚   â”‚    - clean(text) â†’ normalized text
â”‚   â”‚   â”‚   â”‚    - split_sentences(text) â†’ List[str]
â”‚   â”‚   â”‚   â”‚    - tokenize(text) â†’ List[str]
â”‚   â”‚   â”‚   â”‚  Used by: app.py, reasoning/verifiable_pipeline.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ ocr_processor.py                ğŸ“· OCR EXTRACTION
â”‚       â”‚  Lines: ~150
â”‚       â”‚  Purpose: Extract text from images using EasyOCR
â”‚       â”‚  Classes: OCRProcessor
â”‚       â”‚  Models:
â”‚       â”‚    - EasyOCR (language-specific, ~200MB per language)
â”‚       â”‚  Methods:
â”‚       â”‚    - extract_text(image) â†’ str
â”‚       â”‚    - extract_with_confidence(image) â†’ List[(text, confidence)]
â”‚       â”‚  Quality: 70-90% accuracy depending on image
â”‚       â”‚  Used by: app.py
â”‚       â”‚  Status: Production-ready
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ audio/                             ğŸµ AUDIO PROCESSING
â”‚   â”‚   â”‚  Purpose: Transcribe audio to text
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ whisper_transcriber.py          ğŸ™ï¸ SPEECH-TO-TEXT
â”‚       â”‚  Lines: ~100
â”‚       â”‚  Purpose: Transcribe audio using OpenAI Whisper
â”‚       â”‚  Classes: WhisperTranscriber
â”‚       â”‚  Models:
â”‚       â”‚    - Whisper (base/small/medium/large, ~1-3GB)
â”‚       â”‚  Methods:
â”‚       â”‚    - transcribe(audio_file) â†’ str
â”‚       â”‚    - transcribe_with_timestamps(audio_file) â†’ List[(text, timestamp)]
â”‚       â”‚  Used by: app.py
â”‚       â”‚  Status: Production-ready
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ evaluation/                        ğŸ“Š ANALYSIS & METRICS
â”‚   â”‚   â”‚  Purpose: Evaluate and calibrate verification system
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ verifiability_metrics.py        ğŸ“ˆ BASIC METRICS
â”‚   â”‚   â”‚   â”‚  Lines: ~100
â”‚   â”‚   â”‚   â”‚  Purpose: Compute verification rates
â”‚   â”‚   â”‚   â”‚  Metrics:
â”‚   â”‚   â”‚   â”‚    - Rejection rate (% REJECTED)
â”‚   â”‚   â”‚   â”‚    - Verification rate (% VERIFIED)
â”‚   â”‚   â”‚   â”‚    - Uncertainty rate (% LOW_CONFIDENCE)
â”‚   â”‚   â”‚   â”‚  Used by: app.py, evaluation/compare_modes.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ calibration.py                  ğŸ¯ CALIBRATION METRICS âœ¨ NEW
â”‚       â”‚  Lines: 400+
â”‚       â”‚  Purpose: Assess and improve confidence calibration
â”‚       â”‚  Classes: CalibrationAnalyzer
â”‚       â”‚  Metrics:
â”‚       â”‚    - ECE (Expected Calibration Error)
â”‚       â”‚    - Brier score
â”‚       â”‚    - Accuracy metrics
â”‚       â”‚    - Confidence-accuracy bins
â”‚       â”‚  Methods:
â”‚       â”‚    - compute_ece(predictions, labels) â†’ float
â”‚       â”‚    - compute_brier_score(predictions, labels) â†’ float
â”‚       â”‚    - plot_reliability_diagram() â†’ Image
â”‚       â”‚  Used by: app.py, evaluation/compare_modes.py
â”‚       â”‚  Status: Production-ready (Feb 2025)
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ display/                           ğŸ¨ UI COMPONENTS
â”‚   â”‚   â”‚  Purpose: Streamlit UI rendering
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ interactive_claims.py           ğŸ“‹ CLAIMS TABLE
â”‚   â”‚   â”‚   â”‚  Lines: ~200
â”‚   â”‚   â”‚   â”‚  Purpose: Render claims in interactive Streamlit table
â”‚   â”‚   â”‚   â”‚  Functions:
â”‚   â”‚   â”‚   â”‚    - display_claims_interactive(claims)
â”‚   â”‚   â”‚   â”‚    - filter_by_status(claims, status)
â”‚   â”‚   â”‚   â”‚    - sort_by_confidence(claims)
â”‚   â”‚   â”‚   â”‚  Features:
â”‚   â”‚   â”‚   â”‚    - Search across claims
â”‚   â”‚   â”‚   â”‚    - Filter by status
â”‚   â”‚   â”‚   â”‚    - Sort by confidence
â”‚   â”‚   â”‚   â”‚  Used by: app.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ research_assessment_ui.py       ğŸ“Š METRICS DASHBOARD
â”‚   â”‚   â”‚   â”‚  Lines: ~300
â”‚   â”‚   â”‚   â”‚  Purpose: Render calibration metrics + plots
â”‚   â”‚   â”‚   â”‚  Functions:
â”‚   â”‚   â”‚   â”‚    - display_metrics_summary()
â”‚   â”‚   â”‚   â”‚    - display_reliability_diagram()
â”‚   â”‚   â”‚   â”‚    - display_confidence_distribution()
â”‚   â”‚   â”‚   â”‚  Used by: app.py
â”‚   â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ streamlit_display.py            ğŸ¨ DISPLAY UTILS
â”‚       â”‚  Lines: ~150
â”‚       â”‚  Purpose: General Streamlit display utilities
â”‚       â”‚  Functions:
â”‚       â”‚    - show_metric_cards(metrics)
â”‚       â”‚    - show_graph(graph)
â”‚       â”‚    - show_download_buttons(results)
â”‚       â”‚  Used by: app.py
â”‚       â”‚  Status: Production-ready
â”‚       â”‚
â”‚
â”‚   â”œâ”€â”€ ğŸ“ study_book/                        ğŸ“š SESSION AGGREGATION
â”‚   â”‚   â”‚  Purpose: Combine results from multiple sessions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                     (Package marker)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ aggregator.py                   ğŸ“– STUDY GUIDE GENERATION
â”‚       â”‚  Lines: ~200
â”‚       â”‚  Purpose: Aggregate claims from multiple sessions into study guide
â”‚       â”‚  Classes: StudyBookAggregator
â”‚       â”‚  Methods:
â”‚       â”‚    - aggregate_sessions(sessions) â†’ StudyGuide
â”‚       â”‚    - dedup_claims() â†’ unique claims
â”‚       â”‚    - organize_by_topic() â†’ topic hierarchy
â”‚       â”‚  Used by: app.py (advanced features)
â”‚       â”‚  Status: Production-ready
â”‚       â”‚
â”‚
â”‚   â””â”€â”€ ğŸ“ schema/                            ğŸ“Š SCHEMA DEFINITIONS
       â”‚  Purpose: Shared schema definitions
       â”‚
       â””â”€â”€ ğŸ“„ __init__.py                     (Package marker)
          â”‚
          â””â”€â”€ (Most schemas in claims/schema.py)
          â”‚
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  evaluation/ DIRECTORY (Standalone Analysis Tools)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“ evaluation/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                         (Package marker)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ compare_modes.py                    ğŸ”€ MODE COMPARISON âœ¨ NEW
â”‚   â”‚   â”‚  Lines: 500+
â”‚   â”‚   â”‚  Purpose: Compare Baseline vs Verifiable mode performance
â”‚   â”‚   â”‚  Classes: ModeComparator
â”‚   â”‚   â”‚  Analysis:
â”‚   â”‚   â”‚    - Speed comparison
â”‚   â”‚   â”‚    - Accuracy comparison
â”‚   â”‚   â”‚    - Resource usage
â”‚   â”‚   â”‚  Output: Side-by-side report
â”‚   â”‚   â”‚  Status: Production-ready (Feb 2025)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ benchmark.py                       âš¡ PERFORMANCE TESTS
       â”‚  Lines: ~200
       â”‚  Purpose: Benchmark system performance
       â”‚  Tests:
       â”‚    - Generation speed
       â”‚    - Verification speed
       â”‚    - Memory usage
       â”‚  Used by: Developers, performance tuning
       â”‚  Status: Production-ready
       â”‚
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  tests/ DIRECTORY (Test Suite - 21/21 PASSING)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                         (Package marker)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ test_graph_sanitize.py              âœ… GRAPH TESTS âœ¨ NEW (Feb 2025)
â”‚   â”‚   â”‚  Lines: 378
â”‚   â”‚   â”‚  Tests: 18 unit tests
â”‚   â”‚   â”‚  Coverage:
â”‚   â”‚   â”‚    - Sanitization (bytes, enums, Pydantic, dicts, strings)
â”‚   â”‚   â”‚    - GraphML export (string, bytes)
â”‚   â”‚   â”‚    - Graph attribute handling
â”‚   â”‚   â”‚    - GraphMetrics backward compatibility
â”‚   â”‚   â”‚  Status: âœ… ALL PASSING (0.29s)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ test_integration_graph_fixes.py     âœ… INTEGRATION TESTS âœ¨ NEW (Feb 2025)
â”‚   â”‚   â”‚  Lines: 258
â”‚   â”‚   â”‚  Tests: 4 end-to-end tests
â”‚   â”‚   â”‚  Coverage:
â”‚   â”‚   â”‚    - GraphMetrics.get() compatibility
â”‚   â”‚   â”‚    - GraphML export with complex attributes
â”‚   â”‚   â”‚    - ClaimGraph integration
â”‚   â”‚   â”‚    - Pydantic model sanitization
â”‚   â”‚   â”‚  Status: âœ… ALL PASSING
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ pytest.ini                         âš™ï¸ PYTEST CONFIG
       â”‚  Configuration for test discovery
       â”‚  Settings: testpaths, python_files, etc.
       â”‚
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  docs/ DIRECTORY (Technical Documentation)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ README.md                          ğŸ“– Technical README
â”‚   â”‚   â”‚  Technical overview and getting started
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                    ğŸ—ï¸ ARCHITECTURE (via TECHNICAL_DOCUMENTATION.md)
â”‚   â”‚   â”‚  System architecture and design
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ CHANGELOG_FEB2025.md                ğŸ“‹ CHANGELOG âœ¨ NEW
â”‚   â”‚   â”‚  Lines: ~600
â”‚   â”‚   â”‚  Detailed changelog of Feb 2025 fixes
â”‚   â”‚   â”‚  Sections:
â”‚   â”‚   â”‚    - Breaking changes (none)
â”‚   â”‚   â”‚    - New features
â”‚   â”‚   â”‚    - Bug fixes (7 critical issues)
â”‚   â”‚   â”‚    - Migration guide
â”‚   â”‚   â”‚  Status: Complete (Feb 2025)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ IMPLEMENTATION_SUMMARY.md           ğŸ“„ IMPLEMENTATION âœ¨ NEW
â”‚   â”‚   â”‚  Lines: ~1000
â”‚   â”‚   â”‚  Detailed implementation guide
â”‚   â”‚   â”‚  Covers:
â”‚   â”‚   â”‚    - Architecture and components
â”‚   â”‚   â”‚    - Data flow
â”‚   â”‚   â”‚    - Module specifications
â”‚   â”‚   â”‚    - Integration points
â”‚   â”‚   â”‚  Status: Complete (Feb 2025)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ COMPLETION_REPORT.md                âœ… COMPLETION âœ¨ NEW
â”‚   â”‚   â”‚  Lines: ~600
â”‚   â”‚   â”‚  Final project status report
â”‚   â”‚   â”‚  Contents:
â”‚   â”‚   â”‚    - All tasks completed (8/8)
â”‚   â”‚   â”‚    - All tests passing (21/21)
â”‚   â”‚   â”‚    - Performance metrics
â”‚   â”‚   â”‚    - Production status
â”‚   â”‚   â”‚  Status: Complete (Feb 2025)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ TECHNICAL_DOCUMENTATION.md          ğŸ”§ TECHNICAL DOCS âœ¨ NEW
â”‚   â”‚   â”‚  Lines: 3000+
â”‚   â”‚   â”‚  Complete technical documentation
â”‚   â”‚   â”‚  Includes:
â”‚   â”‚   â”‚    - System architecture
â”‚   â”‚   â”‚    - Data flow diagrams
â”‚   â”‚   â”‚    - File structure
â”‚   â”‚   â”‚    - Module specs
â”‚   â”‚   â”‚    - Component interactions
â”‚   â”‚   â”‚    - Data models
â”‚   â”‚   â”‚    - APIs
â”‚   â”‚   â”‚    - Algorithms
â”‚   â”‚   â”‚    - Configuration
â”‚   â”‚   â”‚    - Error handling
â”‚   â”‚   â”‚  Status: Complete (Feb 2025)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ FILE_STRUCTURE.md                   ğŸ“ FILE STRUCTURE âœ¨ NEW
â”‚   â”‚   â”‚  Lines: 1000+
â”‚   â”‚   â”‚  Complete file structure documentation
â”‚   â”‚   â”‚  Includes:
â”‚   â”‚   â”‚    - File tree
â”‚   â”‚   â”‚    - Directory organization
â”‚   â”‚   â”‚    - Module dependencies
â”‚   â”‚   â”‚    - File categories
â”‚   â”‚   â”‚    - Import patterns
â”‚   â”‚   â”‚    - Cache/output structure
â”‚   â”‚   â”‚  Status: This file!
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ API.md                             ğŸ”Œ API REFERENCE
       â”‚  API specifications and usage examples
       â”‚
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  examples/ DIRECTORY (Usage Examples & Demo Data)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“ examples/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                         (Package marker)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ demo_usage.py                       ğŸ’¡ USAGE EXAMPLES
â”‚   â”‚   â”‚  Lines: ~200
â”‚   â”‚   â”‚  Purpose: Demonstrate API usage
â”‚   â”‚   â”‚  Examples:
â”‚   â”‚   â”‚    - Baseline pipeline
â”‚   â”‚   â”‚    - Verifiable pipeline
â”‚   â”‚   â”‚    - Graph visualization
â”‚   â”‚   â”‚    - Export formats
â”‚   â”‚   â”‚  Status: Production-ready
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ verifiable_mode_demo.py             ğŸ“Š VERIFIABLE DEMO âœ¨ NEW
â”‚   â”‚   â”‚  Lines: ~300
â”‚   â”‚   â”‚  Purpose: Demonstrate verifiable mode in detail
â”‚   â”‚   â”‚  Includes:
â”‚   â”‚   â”‚    - Step-by-step verification
â”‚   â”‚   â”‚    - Confidence scoring
â”‚   â”‚   â”‚    - Graph analysis
â”‚   â”‚   â”‚  Status: Production-ready (Feb 2025)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ sample_input.json                   ğŸ“‹ SAMPLE INPUT
â”‚   â”‚   â”‚  Example JSON input for testing
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ README_EXAMPLES.md                  ğŸ“– EXAMPLES README
â”‚   â”‚   â”‚  Usage guide for examples/
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ audio/                             ğŸµ AUDIO SAMPLES
â”‚   â”‚   â”‚  Audio files for testing
â”‚   â”‚   â”‚  (If used in development)
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ inputs/                            ğŸ“¥ TEST INPUTS
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ example1.json                  Sample input 1
â”‚   â”‚   â””â”€â”€ ğŸ“„ example2.json                  Sample input 2
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ notes/                             ğŸ“ SAMPLE NOTES
       â”‚
       â”œâ”€â”€ ğŸ“„ notes1.txt                      Sample notes 1
       â””â”€â”€ ğŸ“„ notes2.txt                      Sample notes 2
â”‚
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  DATA DIRECTORIES (Auto-created at runtime)
â”‚â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚
â”œâ”€â”€ ğŸ“ outputs/                               ğŸ“¤ USER OUTPUTS (Auto-created)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ sessions/                          ğŸ’¾ SAVED SESSIONS
â”‚   â”‚   â”‚  JSON files of processed sessions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ session_20260131_163827.json   Session result (JSON)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ session_20260131_163906.json
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ session_20260201_103004.json
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ session_20260209_175725.json
â”‚   â”‚   â””â”€â”€ ... (30+ session files)
â”‚   â”‚
â”‚   â”‚  Each contains:
â”‚   â”‚    - All claims with confidence + status
â”‚   â”‚    - Evidence for each claim
â”‚   â”‚    - Graph metrics
â”‚   â”‚    - Timestamp
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ evaluation/                        ğŸ“Š ANALYSIS OUTPUTS
       â”‚  Calibration plots and reports
       â”‚
       â”œâ”€â”€ ğŸ“„ calibration_metrics.json        ECE, Brier score
       â”œâ”€â”€ ğŸ“„ reliability_diagram.png         Calibration plot
       â””â”€â”€ ğŸ“„ mode_comparison.html            Baseline vs Verifiable
â”‚
â”œâ”€â”€ ğŸ“ cache/                                 ğŸ’¾ LOCAL CACHING
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ ocr_cache.json                    âš¡ OCR Results Cache
â”‚   â”‚   â”‚  Caches EasyOCR results to avoid re-processing
â”‚   â”‚   â”‚  Format: {image_hash: {text, confidence, timestamp}}
â”‚   â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ faiss_index/                      ğŸ” FAISS INDEXES
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ index_session1.faiss          Per-session FAISS index
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ index_session2.faiss
â”‚   â”‚   â””â”€â”€ ğŸ“„ metadata_session1.json        Index metadata
â”‚   â”‚
â”‚   â”‚  Enables fast evidence retrieval
â”‚   â”‚  Built from source corpus
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ api_responses/                    ğŸ¤– API RESPONSE CACHE
       â”‚  Cache LLM responses to avoid re-querying
       â”‚  Reduces API costs
       â”‚
       â”œâ”€â”€ ğŸ“„ openai_response_hash1.json
       â””â”€â”€ ğŸ“„ openai_response_hash2.json
â”‚
â””â”€â”€ ğŸ“ logs/                                  ğŸ“Š LOGGING OUTPUT
    â”‚
    â”œâ”€â”€ ğŸ“„ app.log                            ğŸ“ ALL LOGS
    â”‚   â”‚  All log messages (DEBUG, INFO, WARNING)
    â”‚   â”‚  Format: timestamp - module - level - message
    â”‚   â”‚
    â”‚
    â””â”€â”€ ğŸ“„ errors.log                         âš ï¸ ERROR LOGS
        â”‚  Errors only (ERROR, CRITICAL)
        â”‚  For quick error diagnosis
        â”‚
```

---

## Directory Organization

### Source Code Organization (src/)

```
src/
â”œâ”€â”€ Core Infrastructure (utility + abstraction)
â”‚   â”œâ”€â”€ llm_provider.py       â”€â†’ LLM abstraction
â”‚   â”œâ”€â”€ logging_config.py     â”€â†’ Logging setup
â”‚   â”œâ”€â”€ output_formatter.py   â”€â†’ Export formatting
â”‚   â””â”€â”€ streamlit_display.py  â”€â†’ UI utilities
â”‚
â”œâ”€â”€ Claim Processing (claims/)
â”‚   â”œâ”€â”€ schema.py             â”€â†’ Data models
â”‚   â”œâ”€â”€ extractor.py          â”€â†’ Extract claims
â”‚   â”œâ”€â”€ validator.py          â”€â†’ Assign status
â”‚   â”œâ”€â”€ nli_verifier.py       â”€â†’ Verify entailment
â”‚   â””â”€â”€ confidence.py         â”€â†’ Score confidence
â”‚
â”œâ”€â”€ Evidence Retrieval (retrieval/)
â”‚   â”œâ”€â”€ claim_rag.py          â”€â†’ Legacy keyword search
â”‚   â””â”€â”€ semantic_retriever.py â”€â†’ Dense + re-rank
â”‚
â”œâ”€â”€ LLM Pipelines (reasoning/)
â”‚   â”œâ”€â”€ pipeline.py           â”€â†’ Baseline generation
â”‚   â”œâ”€â”€ verifiable_pipeline.py â”€â†’ Verification orchestration
â”‚   â””â”€â”€ prompts.py            â”€â†’ LLM prompts
â”‚
â”œâ”€â”€ Graph Analysis (graph/)
â”‚   â”œâ”€â”€ claim_graph.py        â”€â†’ Build + analyze
â”‚   â””â”€â”€ graph_sanitize.py     â”€â†’ Export sanitization
â”‚
â”œâ”€â”€ Input Processing
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ text_processor.py â”€â†’ Text cleaning
â”‚   â”‚   â””â”€â”€ ocr_processor.py  â”€â†’ OCR extraction
â”‚   â”‚
â”‚   â””â”€â”€ audio/
â”‚       â””â”€â”€ whisper_transcriber.py â”€â†’ Speech-to-text
â”‚
â”œâ”€â”€ Analysis (evaluation/)
â”‚   â”œâ”€â”€ verifiability_metrics.py â”€â†’ Basic metrics
â”‚   â””â”€â”€ calibration.py        â”€â†’ Calibration analysis
â”‚
â”œâ”€â”€ UI Components (display/)
â”‚   â”œâ”€â”€ interactive_claims.py â”€â†’ Claims table
â”‚   â”œâ”€â”€ research_assessment_ui.py â”€â†’ Metrics dashboard
â”‚   â””â”€â”€ streamlit_display.py  â”€â†’ General utilities
â”‚
â”œâ”€â”€ Advanced Features
â”‚   â”œâ”€â”€ study_book/
â”‚   â”‚   â””â”€â”€ aggregator.py     â”€â†’ Multi-session aggregation
â”‚   â”‚
â”‚   â””â”€â”€ schema/               â”€â†’ (Mostly in claims/schema.py)
```

### Dependency Hierarchy

```
Top Level (User-facing):
  app.py (Streamlit UI)
    â†“
  reasoning/ (LLM Pipelines)
    â”œâ”€â†’ pipeline.py (Baseline generation)
    â””â”€â†’ verifiable_pipeline.py (Orchestration)
         â”œâ”€â†’ claims/ (Claim processing)
         â”‚    â”œâ”€â†’ extractor.py
         â”‚    â”œâ”€â†’ nli_verifier.py
         â”‚    â”œâ”€â†’ confidence.py
         â”‚    â””â”€â†’ validator.py
         â”œâ”€â†’ retrieval/ (Evidence search)
         â”‚    â””â”€â†’ semantic_retriever.py
         â””â”€â†’ graph/ (Graph analysis)
              â”œâ”€â†’ claim_graph.py
              â””â”€â†’ graph_sanitize.py

Support Layers:
  preprocessing/ (Text/image/audio processing)
  evaluation/ (Metrics + calibration)
  display/ (UI components)
  output_formatter.py (Export formatting)
  llm_provider.py (LLM abstraction)
  logging_config.py (Logging)

Data:
  claims/schema.py (Data models)
  graph_sanitize.py (Type conversion)
```

---

## Module Dependency Graph

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   app.py    â”‚ (Streamlit UI)
                          â”‚  (Main)     â”‚
                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                     â”‚                     â”‚
           â†“                     â†“                     â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Baselineâ”‚        â”‚  Verifiable  â”‚     â”‚  Display/Exportâ”‚
      â”‚Pipeline â”‚        â”‚  Pipeline    â”‚     â”‚  Components    â”‚
      â”‚ (Fast)  â”‚        â”‚  (Detailed)  â”‚     â”‚                â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                    â”‚                      â”‚
           â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
           â”‚             â”‚                     â”‚      â”‚
           â†“             â†“                     â†“      â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚        Claim Processing (claims/)                  â”‚
      â”‚  â”œâ”€ schema.py (Data models)                        â”‚
      â”‚  â”œâ”€ extractor.py (Extract claims)                  â”‚
      â”‚  â”œâ”€ nli_verifier.py (Verify entailment)            â”‚
      â”‚  â”œâ”€ confidence.py (Score confidence)               â”‚
      â”‚  â””â”€ validator.py (Assign status)                   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
         â†“             â†“             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Graph  â”‚  â”‚ Evidence â”‚  â”‚ Evaluation   â”‚
    â”‚ (graph)â”‚  â”‚ Search   â”‚  â”‚ (evaluation) â”‚
    â”‚        â”‚  â”‚(retrieval)â”‚  â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚
         â†“             â†“             â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚        Utilities & Infrastructure       â”‚
  â”‚  â”œâ”€ preprocessing/ (Input cleaning)     â”‚
  â”‚  â”œâ”€ audio/ (Speech-to-text)             â”‚
  â”‚  â”œâ”€ output_formatter.py (Export)        â”‚
  â”‚  â”œâ”€ llm_provider.py (LLM abstraction)   â”‚
  â”‚  â”œâ”€ logging_config.py (Logging)         â”‚
  â”‚  â””â”€ streamlit_display.py (UI utils)     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Categories & Purposes

### By Functional Area

#### **LLM Integration**
- `src/llm_provider.py` - Abstraction for OpenAI/Ollama
- `src/reasoning/pipeline.py` - Baseline generation
- `src/reasoning/verifiable_pipeline.py` - Verification orchestration
- `src/reasoning/prompts.py` - LLM prompts

#### **Data Models**
- `src/claims/schema.py` - Pydantic models (LearningClaim, EvidenceItem, etc.)

#### **Verification Pipeline**
- `src/retrieval/semantic_retriever.py` - Evidence retrieval (FAISS)
- `src/claims/nli_verifier.py` - Entailment verification (NLI)
- `src/claims/confidence.py` - Confidence scoring
- `src/claims/validator.py` - Status assignment

#### **Input Processing**
- `src/preprocessing/text_processor.py` - Text cleaning
- `src/preprocessing/ocr_processor.py` - Image OCR
- `src/audio/whisper_transcriber.py` - Speech-to-text

#### **Graph Analysis**
- `src/graph/claim_graph.py` - Graph construction
- `src/graph/graph_sanitize.py` - Export sanitization

#### **Analysis & Metrics**
- `src/evaluation/verifiability_metrics.py` - Rejection/verification rates
- `src/evaluation/calibration.py` - ECE and calibration

#### **UI & Display**
- `app.py` - Main Streamlit application
- `src/display/interactive_claims.py` - Claims table
- `src/display/research_assessment_ui.py` - Metrics dashboard
- `src/streamlit_display.py` - Display utilities

#### **Export & Formatting**
- `src/output_formatter.py` - JSON/CSV/Markdown export
- `src/graph/graph_sanitize.py` - GraphML export

#### **Configuration**
- `config.py` - Global parameters
- `.env` - Secrets (user-created)

#### **Infrastructure**
- `src/logging_config.py` - Logging setup
- `src/llm_provider.py` - LLM provider abstraction

---

## Import Patterns

### Standard Imports (Production)

```python
# Standard library
import os
import json
import logging
from typing import List, Dict, Optional
from datetime import datetime
import uuid

# Third-party
import numpy as np
import pandas as pd
import streamlit as st
import networkx as nx
from pydantic import BaseModel, Field

# From transformers (NLP models)
from sentence_transformers import SentenceTransformer, util
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import faiss

# Smart Notes modules
from src.claims.schema import LearningClaim, EvidenceItem, GraphMetrics
from src.retrieval.semantic_retriever import SemanticRetriever
from src.claims.nli_verifier import NLIVerifier
from src.claims.confidence import ConfidenceCalculator
from src.graph.claim_graph import ClaimGraph
from src.output_formatter import OutputFormatter
from config import VERIFIED_THRESHOLD, NLI_MODEL
```

### Common Import Blocks by Module

#### **Claim Processing** (src/claims/*.py)
```python
from src.claims.schema import LearningClaim, EvidenceItem, VerificationStatus
from config import VERIFIED_THRESHOLD, REJECT_THRESHOLD
import logging
logger = logging.getLogger(__name__)
```

#### **Graph Operations** (src/graph/*.py)
```python
import networkx as nx
from src.claims.schema import LearningClaim, GraphMetrics
from src.graph.graph_sanitize import sanitize_graph_for_graphml
```

#### **LLM Pipelines** (src/reasoning/*.py)
```python
from src.llm_provider import LLMProvider
from src.claims.extractor import ClaimExtractor
from src.reasoning.prompts import GENERATION_PROMPT
```

#### **Verification Pipeline** (src/reasoning/verifiable_pipeline.py)
```python
from src.retrieval.semantic_retriever import SemanticRetriever
from src.claims.nli_verifier import NLIVerifier
from src.claims.confidence import ConfidenceCalculator
from src.claims.validator import ClaimValidator
from src.graph.claim_graph import ClaimGraph
```

---

## Configuration & Secrets

### Configuration Files

#### **config.py** (Production Parameters)
```python
# Model selection
EMBEDDING_MODEL = "intfloat/e5-base-v2"
NLI_MODEL = "facebook/bart-large-mnli"
LLM_PROVIDER = "openai"  # or "ollama"

# Thresholds
VERIFIED_THRESHOLD = 0.7
REJECT_THRESHOLD = 0.3

# Retrieval
SEMANTIC_TOP_K = 10
RERANK_TOP_N = 5

# Confidence weights (must sum â‰ˆ 1.0)
CONFIDENCE_WEIGHTS = {
    'similarity': 0.25,
    'entailment': 0.35,
    'diversity': 0.10,
    'count': 0.15,
    'contradiction': -0.10,
    'graph': 0.05
}
```

#### **.env** (Secrets, User-created)
```
# API Keys
OPENAI_API_KEY=sk-...
OLLAMA_BASE_URL=http://localhost:11434

# LLM Provider
LLM_PROVIDER=openai
LLM_MODEL=gpt-4

# Storage
CACHE_DIR=./cache
OUTPUT_DIR=./outputs
LOG_DIR=./logs

# Feature Flags
ENABLE_NLI=true
ENABLE_CALIBRATION=false
```

#### **.env.example** (Template)
```
# Example environment file
# Copy to .env and fill in your values

OPENAI_API_KEY=sk-your-key-here
OLLAMA_BASE_URL=http://localhost:11434
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
```

---

## Cache & Output Directories

### Cache Structure (Auto-created)

```
cache/
â”œâ”€â”€ ocr_cache.json                     âš¡ EasyOCR results
â”‚   {
â”‚       "image_hash_abc123": {
â”‚           "text": "extracted text...",
â”‚           "confidence": 0.85,
â”‚           "timestamp": "2025-02-12T10:30:00"
â”‚       }
â”‚   }
â”‚
â”œâ”€â”€ faiss_index/
â”‚   â”œâ”€â”€ index_session_id_1.faiss       FAISS binary index
â”‚   â”œâ”€â”€ index_session_id_1_metadata.json
â”‚   â”‚   {
â”‚   â”‚       "num_docs": 1000,
â”‚   â”‚       "embedding_dim": 768,
â”‚   â”‚       "model": "intfloat/e5-base-v2",
â”‚   â”‚       "created": "2025-02-12T10:30:00"
â”‚   â”‚   }
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ api_responses/
    â”œâ”€â”€ openai_hash_abc123.json        LLM response cache
    â”‚   {
    â”‚       "prompt": "Generate study notes...",
    â”‚       "response": "Here are the key concepts...",
    â”‚       "model": "gpt-4",
    â”‚       "created": "2025-02-12T10:30:00",
    â”‚       "cost_usd": 0.05
    â”‚   }
    â””â”€â”€ ...
```

### Output Structure (Auto-created)

```
outputs/
â”œâ”€â”€ sessions/                          ğŸ’¾ All session results
â”‚   â”œâ”€â”€ session_20260131_163827.json  (Full result as JSON)
â”‚   â”‚   {
â”‚   â”‚       "session_id": "uuid-1234",
â”‚   â”‚       "timestamp": "2025-01-31T16:38:27",
â”‚   â”‚       "mode": "verifiable",
â”‚   â”‚       "input_type": "text",
â”‚   â”‚       "claims": [...],
â”‚   â”‚       "metrics": {
â”‚   â”‚           "total_claims": 287,
â”‚   â”‚           "verified": 245,
â”‚   â”‚           "rejected": 32,
â”‚   â”‚           "avg_confidence": 0.72
â”‚   â”‚       },
â”‚   â”‚       "processing_time_seconds": 95.3
â”‚   â”‚   }
â”‚   â”œâ”€â”€ session_20260201_103004.json
â”‚   â””â”€â”€ ... (30+ sessions)
â”‚
â””â”€â”€ evaluation/                        ğŸ“Š Analysis outputs
    â”œâ”€â”€ calibration_metrics.json       (ECE, Brier score)
    â”œâ”€â”€ reliability_diagram.png        (Matplotlib plot)
    â”œâ”€â”€ confidence_distribution.png
    â””â”€â”€ mode_comparison_report.html
```

---

## Test Organization

### Test Structure

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ pytest.ini                         Pytest configuration
â”‚   [pytest]
â”‚   testpaths = tests
â”‚   python_files = test_*.py
â”‚   python_classes = Test*
â”‚   python_functions = test_*
â”‚
â”œâ”€â”€ test_graph_sanitize.py             âœ¨ GRAPH SANITIZATION (NEW - Feb 2025)
â”‚   â”‚
â”‚   â”œâ”€â”€ class TestSanitizeValue
â”‚   â”‚   â”œâ”€â”€ test_sanitize_string()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_bytes_utf8()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_bytes_binary()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_enum()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_dict()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_list()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_pydantic_model()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_datetime()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_none()
â”‚   â”‚   â”œâ”€â”€ test_sanitize_long_string()
â”‚   â”‚   â””â”€â”€ test_sanitize_nested_structures()
â”‚   â”‚
â”‚   â”œâ”€â”€ class TestSanitizeGraphForGraphML
â”‚   â”‚   â”œâ”€â”€ test_graph_node_attributes()
â”‚   â”‚   â”œâ”€â”€ test_graph_edge_attributes()
â”‚   â”‚   â”œâ”€â”€ test_graph_with_mixed_types()
â”‚   â”‚   â””â”€â”€ test_graph_preserves_structure()
â”‚   â”‚
â”‚   â”œâ”€â”€ class TestExportGraphML
â”‚   â”‚   â”œâ”€â”€ test_export_graphml_string()
â”‚   â”‚   â”œâ”€â”€ test_export_graphml_bytes()
â”‚   â”‚   â””â”€â”€ test_graphml_valid_xml()
â”‚   â”‚
â”‚   â””â”€â”€ class TestGraphMetricsCompatibility
â”‚       â”œâ”€â”€ test_graphmetrics_to_dict()
â”‚       â””â”€â”€ test_graphmetrics_get_method()
â”‚
â”‚   Status: âœ… 18 tests, 100% passing (0.29s)
â”‚
â”‚
â””â”€â”€ test_integration_graph_fixes.py    âœ¨ INTEGRATION TESTS (NEW - Feb 2025)
    â”‚
    â”œâ”€â”€ class TestGraphFixes
    â”‚   â”œâ”€â”€ test_graph_metrics_get()
    â”‚   â”œâ”€â”€ test_graphml_export_with_complex_attributes()
    â”‚   â”œâ”€â”€ test_claim_graph_integration()
    â”‚   â””â”€â”€ test_pydantic_model_in_graph()
    â”‚
    Status: âœ… 4 tests, 100% passing
```

### Running Tests

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_graph_sanitize.py

# Run with verbose output
pytest -v

# Run with coverage
pytest --cov=src

# Run single test
pytest tests/test_graph_sanitize.py::TestSanitizeValue::test_sanitize_enum
```

---

## Documentation Files

### Documentation Hierarchy

```
Root README.md (1585 lines)
â”œâ”€ Quick Start
â”œâ”€ Installation
â”œâ”€ Usage Examples
â”œâ”€ System Status âœ… Production Ready
â”œâ”€ Performance Benchmarks
â””â”€ Troubleshooting

docs/
â”œâ”€â”€ README.md                          Technical README
â”œâ”€â”€ TECHNICAL_DOCUMENTATION.md         ğŸ”§ COMPLETE TECHNICAL GUIDE
â”‚   â””â”€ Architecture, data flow, modules, algorithms
â”œâ”€â”€ FILE_STRUCTURE.md                  ğŸ“ FILE STRUCTURE (THIS FILE)
â”‚   â””â”€ Complete file tree and organization
â”œâ”€â”€ CHANGELOG_FEB2025.md               ğŸ“‹ CHANGELOG
â”‚   â””â”€ All changes in February 2025
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md          ğŸ“„ IMPLEMENTATION
â”‚   â””â”€ Detailed implementation guide
â”œâ”€â”€ COMPLETION_REPORT.md               âœ… COMPLETION
â”‚   â””â”€ Final project status
â””â”€â”€ API.md                             ğŸ”Œ API REFERENCE
    â””â”€ Public API specifications

examples/
â”œâ”€â”€ demo_usage.py                      ğŸ’¡ USAGE EXAMPLES
â”œâ”€â”€ verifiable_mode_demo.py            ğŸ“Š VERIFIABLE DEMO
â””â”€â”€ README_EXAMPLES.md                 ğŸ“– EXAMPLES README
```

---

**End of File Structure Documentation**

For navigation:
- Architecture & algorithms â†’ [TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)
- Changes & updates â†’ [CHANGELOG_FEB2025.md](docs/CHANGELOG_FEB2025.md)
- API usage â†’ [README.md](README.md) or examples/
- Project status â†’ [COMPLETION_REPORT.md](docs/COMPLETION_REPORT.md)
